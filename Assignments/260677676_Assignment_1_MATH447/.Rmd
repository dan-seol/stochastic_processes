---
title: "MATH 447 - Assignment 1"
output:
  pdf_document: default
  word_document: default
  html_document: default
header-includes: \usepackage{blkarray}
---
Dan Yunheum Seol
260677676

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 1.17
We have
$$
X \sim Pois(\lambda) : \lambda = 3
$$
and we need to obtain
$$
E[X|X > 2]
$$

We use the Law of Iterated Expectation
$$
\lambda = E[X] = E[E[X|X>2]] = E[X|X>2]P(X >2) + E[X| X \leq 2] P(X \leq 2)
$$
It follows that
$$
E[X|X>2] = \frac{E[X]-E[X|X \leq 2]}{P(X \leq 2)} = \frac{\lambda - \sum_{x=0}^2 x  \frac{e^{-\lambda} \lambda^x}{x!} }{\sum_{x=0}^2   \frac{e^{-\lambda} \lambda^x}{x!}} = \frac{3 - (0 + 3e^{-3} + 9e^{-3})}{e^{-3} + 3*e^{-3}+\frac{9}{2}e^{-3}}
$$
R gives the result of
```{r}
round((3-3*exp(-3)*(1+3))/(1-(exp(-3)+3*exp(-3)+4.5*exp(-3))), 5)

```
$\square$

## 1. 28

We have
$$
N := \text{The number of accidents};\ N|\Lambda \sim Pois(\Lambda);\ \Lambda \sim U(0,3)
$$
Then by the Laws of Iterated Expectation and Iterated Variance,
$$
E[N] = E_{\Lambda}[E_{N}[N| \Lambda]] = E_{\Lambda}[\Lambda] = \frac{3-0}{2} = \frac{3}{2}
$$

$$
Var[N] = E[Var[N|\Lambda]] + Var[E[N|\Lambda]] = E[\Lambda] + Var[\Lambda] = \frac{3}{2} + (\int_0^3 \frac{1}{3} \Lambda^2 d \Lambda - \frac{9}{4} ) = \frac{3}{2} + \frac{\Lambda^3}{9}|^3_0 - \frac{9}{4} =
$$

$$
\frac{3}{2} + (3 - \frac{9}{4}) =  \frac{6}{4} + \frac{3}{4} = \frac{9}{4}
$$


## 2.2
We have
$(\{X_t\}_{t \in \mathbb{N}_0} , P, \vec{\alpha})$ as our Markov chain with transition probability matrix $P$, and initial distribution $\vec{\alpha}$
We also have that (the blkarray package had some errors.)


$$

P = 
\begin{array}{c|c|c|c}
 & \text{State 1} & \text{State 2} & \text{State 3} \\ 

\text{State 1} & 0.575 & 0.118 & 0.172 \\

\text{State 2} & 0.453 & 0.243 & 0.148 \\
\text{State 3} & 0.104 & 0.343 & 0.367 \\
\end{array} 

$$

$$
\vec{\alpha} = (1/2, 0, 1/2)
$$

###(a)

$$
P(X_2 =1 | X_1 = 3) = P(X_1=1 | X_0 = 3) = P_{31} = \frac{1}{3}
$$

###(b)
$$
P(X_2 =1,  X_1 = 3) = (\vec{\alpha}P)_3 P_{31} = \frac{5}{12} * \frac{1}{3} = \frac{5}{36}
$$
```{r}
P1 = matrix(c(0, 0.5, 0.5, 1, 0, 0, 1/3, 1/3, 1/3), nrow=3, ncol=3, byrow=TRUE)
P1
alpha = c(0.5, 0, 0.5)
alpha

alpha %*% P1
((alpha %*% P1)[3]*P1[3][1])
5/36
```

###(c)

$$
P(X_1=3|X_2 = 1) = \frac{P(X_1=3, X_2 =1)}{P(X_2=1)} = \frac{1}{P(X_2=1)} \frac{5}{36}
$$
$$
P(X_2=1) = (\vec{\alpha}P^2)_1 = \frac{60}{108}
$$

### Code for computing $P^n$ from textbook

```{r}
##### Matrix powers ###############################
# matrixpower(mat,k) mat^k
#
matrixpower = function(X, n){
  
  if(dim(X)[1] != dim(X)[2]){
     throw("Dimensions of the matrix do not match: ", dim(X))
  }
  if (n==0){return(diag(dim(X)[1]))}
  else if(n >0) {return(X %*% matrixpower(X, (n-1)))}
  else {return(matrixpower(solve(X), -n))}
}
```

```{r}

P1sq = matrixpower(P1, 2)
P1sq
alphaP1sq.1 = (alpha %*% P1sq)[1]
alphaP1sq.1
60/108
```

$$
P(X_1=3|X_2 = 1) = \frac{108}{60} * \frac{5}{36} =  \frac{1}{4}
$$
```{r}
(5/36)/alphaP1sq.1
```


###(d)

$$
P(X_9=1 | X_1 = 3, X_4=1, X_7=2) = P(X_9=1|X_7=2) = P(X_2=1|X_0=2) = P^2_{21} = 0
$$
by Markov property.
```{r}
P1sq[2][1]
```


##2.7

We have $(\{X_t\}_{t \in \mathbb{N}_0} , P)$, a Markov chain with TPM P.

We need to show that $\{Y_t\} = \{X_{3t}\}$ is a Markov chain and show its TPM.

We show that the property $P(Y_{n+1}=j |Y_n=i , ... Y_0 = i_0) = P(Y_{n+1} = j| Y_n = i) $ for $\forall n \in \mathbb{N}_0$ by induction on n.

###Base case
For n= 0
 
$$
P(Y_1 = j | Y_{1-1} = i) = P(Y_1 = j | Y_0 = i) =  P(X_3 = j | X_0 = i)  = P^3_{ij}
$$

holds trivially.

###Inductive step

Suppose our claim holds for some $n \in \mathbb{N}_0$ i.e.

$$
\exists n: P(Y_{n+1}=j |Y_n=i , ... Y_0 = i_0) = P(Y_{n+1} = j| Y_n = i)
$$

for $n+1$
$$
P(Y_{n+2}=j |Y_{n+1}=i , ... Y_0 = i_0) = P(X_{3n+6}=j |X_{3n+3}=i , ... X_0 = i_0) =
$$
$$
P(X_{3n+6}=j |X_{3n+3}=i) = P(Y_{n+2}=j |Y_{n+1}=i)
$$

by Markov property of $\{X_t\}$.

By this we have shown that $\{Y_t\}$ is a Markov chain. TPM for $\{Y_t\}$ will be $P^3$.

###2.13

$$
\begin{align}
P = 
\begin{array}{c|c|c|c|c|c|c}
 & \text{abc} & \text{acb} & \text{bac} & \text{bca} & \text{cab}  & \text{cba}  \\ 

\text{abc} & \text{p_a} &  \text{p_c} & \text{p_b} & 0& 0&0 \\

\text{acb}& \text{p_b} & \text{p_a} & 0 & 0  & \text{p_c} & 0  \\
\text{bac} & \text{p_a} & 0 & \text{p_b} & \text{p_c} & 0 & 0 \\
\text{bca} & 0 & 0 & \text{p_a} & \text{p_b} & 0 & \text{p_c}  \\
\text{cab} & 0 & \text{p_a} & 0 & 0 & \text{p_c}  & \text{p_b} \\
\text{cba}  & 0 & 0 & 0 & \text{p_b} & \text{p_a} & \text{p_c}  \\ 
\end{array} 
\end{align}
$$

where $\text{p_i} = $ (probability of book i being returned). If p_i = $\frac{1}{3}$ for $\forall i$, we will have

$$
\begin{align}
P = 
\begin{array}{c|c|c|c|c|c|c}
 & \text{abc} & \text{acb} & \text{bac} & \text{bca} & \text{cab}  & \text{cba}  \\ 

\text{abc} & \frac{1}{3} &   \frac{1}{3} &  \frac{1}{3} & 0& 0&0 \\

\text{acb}&  \frac{1}{3} &  \frac{1}{3} & 0 & 0  &  \frac{1}{3} & 0  \\
\text{bac} &  \frac{1}{3} & 0 & \frac{1}{3} & \frac{1}{3} & 0 & 0 \\
\text{bca} & 0 & 0 & \frac{1}{3} &  \frac{1}{3} & 0 &  \frac{1}{3}  \\
\text{cab} & 0 &  \frac{1}{3} & 0 & 0 &  \frac{1}{3}  &  \frac{1}{3} \\
\text{cba}  & 0 & 0 & 0 &  \frac{1}{3} & \frac{1}{3} &  \frac{1}{3} \\ 
\end{array} 
\end{align}
$$